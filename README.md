# ğŸ¦€ Mini-GPT-Rust

> **Um Large Language Model (LLM) completo implementado em Rust com suporte nativo Ã  GPU Metal ARM Apple**

[![Rust](https://img.shields.io/badge/rust-1.70+-orange.svg)](https://www.rust-lang.org)
[![Candle](https://img.shields.io/badge/candle-ML%20Framework-blue.svg)](https://github.com/huggingface/candle)
[![Metal](https://img.shields.io/badge/Metal-GPU%20Accelerated-green.svg)](https://developer.apple.com/metal/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

## ğŸ¯ **VisÃ£o Geral**

Mini-GPT-Rust Ã© uma implementaÃ§Ã£o completa de um modelo GPT (Generative Pre-trained Transformer) em Rust, utilizando o framework [Candle](https://github.com/huggingface/candle) da Hugging Face. O projeto demonstra como construir, treinar e usar um LLM moderno com performance de sistemas e safety garantida pelo Rust.

### âœ¨ **CaracterÃ­sticas Principais**

- ğŸ§  **Arquitetura Transformer Completa**: Self-attention, feed-forward networks, layer normalization
- ğŸš€ **GPU Metal ARM Apple Otimizada**: ConfiguraÃ§Ãµes especÃ­ficas para mÃ¡xima performance
- ğŸ“ **TokenizaÃ§Ã£o BPE**: Byte Pair Encoding para processamento eficiente de texto
- ğŸ‹ï¸ **Treinamento Adaptativo**: ConfiguraÃ§Ãµes dinÃ¢micas baseadas no hardware disponÃ­vel
- ğŸ’¬ **MÃºltiplos Modos**: Treinamento, geraÃ§Ã£o de texto e chat interativo
- ğŸ“ **Sistema Educacional**: Logging detalhado para entender o funcionamento interno dos LLMs
- ğŸ” **AnÃ¡lise de TokenizaÃ§Ã£o**: VisualizaÃ§Ã£o completa do processo de tokenizaÃ§Ã£o
- ğŸ“Š **MÃ©tricas de Performance**: EstatÃ­sticas em tempo real de geraÃ§Ã£o e processamento
- ğŸ’¾ **PersistÃªncia SafeTensors**: Salvamento e carregamento seguro de modelos
- ğŸ›¡ï¸ **Memory Safety**: Garantias de seguranÃ§a de memÃ³ria do Rust
- âš¡ **Zero-Cost Abstractions**: Performance de baixo nÃ­vel com ergonomia de alto nÃ­vel

## ğŸ—ï¸ **Arquitetura do Sistema**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Mini-GPT-Rust                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¯ main.rs              â”‚ Interface principal e modos      â”‚
â”‚  ğŸ§  model.rs             â”‚ Arquitetura GPT e forward pass  â”‚
â”‚  ğŸ—ï¸ transformer.rs       â”‚ Blocos Transformer e Feed-Forwardâ”‚
â”‚  ğŸ‘ï¸ attention.rs         â”‚ Multi-Head Self-Attention       â”‚
â”‚  ğŸ‹ï¸ training.rs          â”‚ Loop de treinamento e otimizaÃ§Ã£o â”‚
â”‚  ğŸ“ tokenizer.rs         â”‚ TokenizaÃ§Ã£o BPE                 â”‚
â”‚  ğŸ“ educational_logger.rs â”‚ Sistema de logging educacional   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Framework Candle                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”¥ Metal GPU ARM Apple â”‚ ğŸ–¥ï¸ CPU Fallback â”‚ ğŸŒ WebGPU        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ **InstalaÃ§Ã£o e ConfiguraÃ§Ã£o**

### **PrÃ©-requisitos**

- **Rust 1.70+**: [Instalar Rust](https://rustup.rs/)
- **macOS com Metal**: Para aceleraÃ§Ã£o GPU (opcional)
- **18GB+ RAM**: Recomendado para treinamento com GPU

### **Clonagem e Build**

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/mini-gpt-rust.git
cd mini-gpt-rust

# Build em modo release (recomendado)
cargo build --release

# Ou build em modo debug para desenvolvimento
cargo build
```

### **DependÃªncias Principais**

```toml
[dependencies]
# Framework Candle com suporte Metal GPU
candle-core = { version = "0.8", features = ["metal"] }
candle-nn = { version = "0.8", features = ["metal"] }
candle-transformers = { version = "0.8", features = ["metal"] }
candle-optimisers = "0.8"     # Otimizadores (Adam, SGD)

# PersistÃªncia e serializaÃ§Ã£o
safetensors = "0.4"           # PersistÃªncia segura de modelos
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# TokenizaÃ§Ã£o e processamento
tokenizers = "0.15"           # TokenizaÃ§Ã£o BPE
unicode-segmentation = "1.10" # SegmentaÃ§Ã£o Unicode PT-BR

# UtilitÃ¡rios e CLI
indicatif = "0.17"            # Barras de progresso
rand = "0.8"                  # GeraÃ§Ã£o de nÃºmeros aleatÃ³rios
anyhow = "1.0"                # Error handling
thiserror = "1.0"             # Error handling estruturado
clap = { version = "4.0", features = ["derive"] }  # CLI
ndarray = "0.15"              # Arrays multidimensionais

# Suporte Metal para macOS
[target.'cfg(target_os = "macos")'.dependencies]
candle-metal-kernels = "0.8"  # Kernels Metal ARM Apple
```

## ğŸ® **Uso do Sistema**

### **1. ğŸ‹ï¸ Treinamento do Modelo**

```bash
# Treinamento bÃ¡sico (salva automaticamente em models/mini_gpt.safetensors)
cargo run --release -- train

# Treinamento com parÃ¢metros customizados
cargo run --release -- train --epochs 10 --data data/corpus_pt_br.txt
```

**SaÃ­da esperada:**
```
âš¡ ConfiguraÃ§Ãµes otimizadas para Metal GPU ARM Apple:
   ğŸ“¦ Batch Size: 32 (4x maior que CPU)
   ğŸ¯ Learning Rate: 1e-4 (otimizado para GPU)
ğŸš€ Inicializando modelo para Metal GPU
   âš¡ PrecisÃ£o: F32 otimizada para Metal
   ğŸ§  MemÃ³ria: Configurado para 18GB ARM Apple
ğŸ‹ï¸ Iniciando treinamento...
Ã‰poca 1/5: Loss mÃ©dio: 7.9030, Velocidade: 1996 tokens/seg
ğŸ’¾ Modelo salvo com sucesso: models/mini_gpt.safetensors (4.0 MB)
```

### **2. ğŸ“ GeraÃ§Ã£o de Texto**

```bash
# GeraÃ§Ã£o simples
cargo run --release -- generate --prompt "O Brasil Ã©" --max-tokens 50

# GeraÃ§Ã£o com parÃ¢metros avanÃ§ados
cargo run --release -- generate --prompt "Era uma vez" --max-tokens 100 --temperature 0.8
```

### **3. ğŸ’¬ Chat Interativo**

```bash
# Modo chat bÃ¡sico
cargo run --release -- chat

# Chat com modo educacional (recomendado para aprendizado)
cargo run --release -- chat --educational --show-tensors

# Chat com entrada via pipe
echo "Conte-me sobre inteligÃªncia artificial" | cargo run --release -- chat
```

#### **ğŸ“ Comandos Especiais do Chat Educacional**

Quando o modo educacional estÃ¡ ativo, vocÃª pode usar:

```bash
/tokens-demo "texto"  # Demonstra tokenizaÃ§Ã£o passo a passo
/explain              # Explica o processo completo de geraÃ§Ã£o
/temp 0.8            # Ajusta temperatura de geraÃ§Ã£o
/tokens 100          # Define mÃ¡ximo de tokens
/stats               # Mostra estatÃ­sticas do modelo
/help                # Lista todos os comandos
```

**Exemplo de saÃ­da educacional:**
```
ğŸ“ MODO EDUCACIONAL ATIVADO
ğŸ“ TokenizaÃ§Ã£o: "OlÃ¡ mundo" â†’ [156, 89, 45]
ğŸ”¢ Embeddings: 512 dimensÃµes por token
ğŸ§  Processamento: 4 camadas Transformer
âš¡ GeraÃ§Ã£o: 23 tokens em 0.45s (51.1 tok/s)
```

## ğŸ’¾ **Sistema de PersistÃªncia SafeTensors**

O Mini-GPT-Rust implementa um sistema robusto de persistÃªncia usando o formato SafeTensors, garantindo seguranÃ§a e portabilidade dos modelos treinados.

### **CaracterÃ­sticas do Sistema**

- **ğŸ”’ Formato Seguro**: SafeTensors previne ataques de deserializaÃ§Ã£o
- **ğŸ“¦ Portabilidade**: Modelos compatÃ­veis entre diferentes plataformas
- **âš¡ Performance**: Carregamento rÃ¡pido com mapeamento de memÃ³ria
- **ğŸ¯ AutomÃ¡tico**: Salvamento automÃ¡tico apÃ³s cada Ã©poca de treinamento
- **ğŸ“ OrganizaÃ§Ã£o**: Estrutura de diretÃ³rios automÃ¡tica (`models/`)

### **Uso do Sistema**

```bash
# Salvamento automÃ¡tico durante treinamento
cargo run --release -- train  # Salva em models/mini_gpt.safetensors

# Verificar modelo salvo
ls -lh models/
# -rw-r--r--  1 user  staff   4.0M  mini_gpt.safetensors
```

### **Estrutura do Arquivo SafeTensors**

```rust
// Tensores salvos automaticamente:
- token_embedding.weight     // Embeddings de tokens
- position_embedding.weight  // Embeddings posicionais  
- transformer.layers.*.ln1   // Layer normalization 1
- transformer.layers.*.ln2   // Layer normalization 2
- transformer.layers.*.attn  // Pesos de atenÃ§Ã£o
- transformer.layers.*.mlp   // Pesos do feed-forward
- lm_head.weight            // CabeÃ§a de linguagem
```

## ğŸ§  **Detalhes TÃ©cnicos**

### **Arquitetura do Modelo**

| Componente | DescriÃ§Ã£o | ImplementaÃ§Ã£o |
|------------|-----------|---------------|
| **Embeddings** | Token + Position embeddings | `nn::Embedding` |
| **Transformer Blocks** | N camadas empilhadas | `TransformerBlock` |
| **Self-Attention** | Multi-head attention | `MultiHeadAttention` |
| **Feed-Forward** | MLP com expansÃ£o 4x | `FeedForward` |
| **Layer Norm** | NormalizaÃ§Ã£o por camada | `nn::LayerNorm` |
| **Language Head** | ProjeÃ§Ã£o para vocabulÃ¡rio | `nn::Linear` |

### **ConfiguraÃ§Ãµes de Hardware**

#### **ğŸ”¥ GPU Metal ARM Apple (Otimizado)**
- **Batch Size**: 32
- **Learning Rate**: 1e-4
- **PrecisÃ£o**: F32 otimizada
- **MemÃ³ria**: Configurado para 18GB
- **Performance**: ~2000 tokens/seg

#### **ğŸ–¥ï¸ CPU (Fallback)**
- **Batch Size**: 8
- **Learning Rate**: 3e-4
- **PrecisÃ£o**: F32 padrÃ£o
- **Performance**: ~6400 tokens/seg

### **TokenizaÃ§Ã£o BPE**

O sistema utiliza Byte Pair Encoding (BPE) para tokenizaÃ§Ã£o eficiente:

```rust
// Tokens especiais
<PAD>  = 0  // Padding
<UNK>  = 1  // Unknown
<BOS>  = 2  // Begin of Sentence
<EOS>  = 3  // End of Sentence
```

## ğŸ“Š **Benchmarks e Performance**

### **Resultados de Treinamento**

| Hardware | Batch Size | Velocidade | Loss Final | Tempo/Ã‰poca |
|----------|------------|------------|------------|-------------|
| Metal ARM Apple | 32 | 1996 tok/s | 7.9030 | 7.21s |
| CPU (Fallback) | 8 | 6413 tok/s | 7.9119 | 2.25s |

### **Uso de MemÃ³ria**

- **Modelo**: ~4MB (parÃ¢metros salvos em SafeTensors)
- **Treinamento**: ~2GB (Metal GPU)
- **InferÃªncia**: ~500MB (Metal GPU)
- **Modelo Salvo**: Formato SafeTensors portÃ¡vel e seguro

## ğŸ”§ **Desenvolvimento e ContribuiÃ§Ã£o**

### **Estrutura do CÃ³digo**

```
src/
â”œâ”€â”€ main.rs              # ğŸš€ CLI e modos de operaÃ§Ã£o
â”œâ”€â”€ model.rs             # ğŸ§  Arquitetura GPT principal
â”œâ”€â”€ transformer.rs       # ğŸ—ï¸ Blocos Transformer
â”œâ”€â”€ attention.rs         # ğŸ‘ï¸ Mecanismo de atenÃ§Ã£o
â”œâ”€â”€ training.rs          # ğŸ‹ï¸ Loop de treinamento + persistÃªncia
â”œâ”€â”€ tokenizer.rs         # ğŸ“ TokenizaÃ§Ã£o BPE
â””â”€â”€ educational_logger.rs # ğŸ“ Sistema de logging educacional

data/
â””â”€â”€ corpus_pt_br.txt     # ğŸ“š Dataset em portuguÃªs brasileiro

models/
â””â”€â”€ mini_gpt.safetensors # ğŸ’¾ Modelo treinado (SafeTensors)

docs/
â””â”€â”€ EDUCATIONAL_LOGGING.md # ğŸ“– DocumentaÃ§Ã£o do sistema educacional
```

### **PadrÃµes de CÃ³digo**

- **Error Handling**: `Result<T>` em todas as operaÃ§Ãµes
- **Memory Safety**: Ownership e borrowing do Rust
- **Performance**: Zero-cost abstractions
- **Documentation**: ComentÃ¡rios detalhados em portuguÃªs

### **Testes**

```bash
# Executar todos os testes
cargo test

# Testes com output detalhado
cargo test -- --nocapture

# Benchmark de performance
cargo bench
```

## ğŸ¯ **Roadmap e Melhorias Futuras**

### **ğŸ”¥ PrÃ³ximas Features**

- [x] **PersistÃªncia SafeTensors**: Salvamento seguro de modelos âœ…
- [ ] **Carregamento de Modelos**: Sistema completo de checkpoint
- [ ] **QuantizaÃ§Ã£o**: Suporte a INT8/FP16 para eficiÃªncia
- [ ] **Distributed Training**: Treinamento distribuÃ­do
- [ ] **Instruction Tuning**: Fine-tuning para seguir instruÃ§Ãµes
- [ ] **RLHF**: Reinforcement Learning from Human Feedback
- [ ] **Multi-Modal**: Suporte a imagens e Ã¡udio

### **ğŸš€ OtimizaÃ§Ãµes Planejadas**

- [ ] **Kernel Fusion**: OtimizaÃ§Ãµes de baixo nÃ­vel
- [x] **Memory Mapping**: Carregamento eficiente com SafeTensors âœ…
- [ ] **Streaming**: GeraÃ§Ã£o de texto em tempo real
- [ ] **Caching**: Cache inteligente de atenÃ§Ã£o
- [ ] **Model Compression**: CompressÃ£o de modelos salvos

### **ğŸ“š Melhorias de Qualidade**

- [ ] **Dataset Expansion**: Mais dados de treinamento
- [ ] **Hyperparameter Tuning**: OtimizaÃ§Ã£o automÃ¡tica
- [ ] **Architecture Improvements**: RoPE, SwiGLU, etc.
- [ ] **Evaluation Metrics**: MÃ©tricas de qualidade

## ğŸ¤ **Contribuindo**

1. **Fork** o projeto
2. **Crie** uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. **Push** para a branch (`git push origin feature/AmazingFeature`)
5. **Abra** um Pull Request

### **Guidelines de ContribuiÃ§Ã£o**

- Siga os padrÃµes de cÃ³digo Rust (use `cargo fmt`)
- Adicione testes para novas funcionalidades
- Documente APIs pÃºblicas
- Mantenha compatibilidade com Metal GPU

## ğŸ“„ **LicenÃ§a**

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ **Agradecimentos**

- **[Hugging Face Candle](https://github.com/huggingface/candle)**: Framework ML em Rust
- **[Attention is All You Need](https://arxiv.org/abs/1706.03762)**: Paper original do Transformer
- **[OpenAI GPT](https://openai.com/research/language-unsupervised)**: Arquitetura GPT
- **Comunidade Rust**: Pelo ecossistema incrÃ­vel

## ğŸ“ **Contato e Suporte**

- **Issues**: [GitHub Issues](https://github.com/seu-usuario/mini-gpt-rust/issues)
- **DiscussÃµes**: [GitHub Discussions](https://github.com/seu-usuario/mini-gpt-rust/discussions)
- **Email**: seu-email@exemplo.com

---

<div align="center">

**ğŸ¦€ Feito com â¤ï¸ em Rust | âš¡ Acelerado por Metal GPU ARM Apple**

</div>