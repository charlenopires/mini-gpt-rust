//! # üî• **DEMONSTRA√á√ÉO: KERNEL FUSION E OTIMIZA√á√ïES DE BAIXO N√çVEL**
//!
//! Este exemplo demonstra as t√©cnicas avan√ßadas de kernel fusion implementadas
//! no Mini GPT, mostrando como opera√ß√µes separadas s√£o combinadas em kernels
//! ultra-eficientes para alcan√ßar speedups de 2-5x.
//!
//! ## üéØ **O QUE VOC√ä VAI APRENDER:**
//!
//! 1. **Kernel Fusion Fundamentals** - Como combinar opera√ß√µes
//! 2. **Fused Attention** - Aten√ß√£o otimizada em um √∫nico kernel
//! 3. **Fused Feed-Forward** - Redes neurais fusionadas
//! 4. **Memory Management** - Gerenciamento inteligente de mem√≥ria
//! 5. **Performance Benchmarks** - Medi√ß√£o de speedups reais
//! 6. **Optimization Strategies** - T√©cnicas avan√ßadas de otimiza√ß√£o

use std::collections::HashMap;
use std::time::{Duration, Instant};

// ============================================================================
// üèóÔ∏è ESTRUTURAS SIMPLIFICADAS PARA DEMONSTRA√á√ÉO
// ============================================================================

#[derive(Debug, Clone)]
pub struct Matrix {
    pub data: Vec<f32>,
    pub rows: usize,
    pub cols: usize,
}

impl Matrix {
    pub fn new(rows: usize, cols: usize) -> Self {
        Self {
            data: vec![0.0; rows * cols],
            rows,
            cols,
        }
    }
    
    pub fn random(rows: usize, cols: usize) -> Self {
        let mut matrix = Self::new(rows, cols);
        for i in 0..matrix.data.len() {
            matrix.data[i] = (i as f32 * 0.1) % 1.0;
        }
        matrix
    }
    
    pub fn get(&self, row: usize, col: usize) -> f32 {
        self.data[row * self.cols + col]
    }
    
    pub fn set(&mut self, row: usize, col: usize, value: f32) {
        self.data[row * self.cols + col] = value;
    }
    
    pub fn matmul(&self, other: &Matrix) -> Matrix {
        assert_eq!(self.cols, other.rows);
        let mut result = Matrix::new(self.rows, other.cols);
        
        for i in 0..self.rows {
            for j in 0..other.cols {
                let mut sum = 0.0;
                for k in 0..self.cols {
                    sum += self.get(i, k) * other.get(k, j);
                }
                result.set(i, j, sum);
            }
        }
        result
    }
    
    pub fn transpose(&self) -> Matrix {
        let mut result = Matrix::new(self.cols, self.rows);
        for i in 0..self.rows {
            for j in 0..self.cols {
                result.set(j, i, self.get(i, j));
            }
        }
        result
    }
    
    pub fn scale(&self, factor: f32) -> Matrix {
        let mut result = self.clone();
        for value in &mut result.data {
            *value *= factor;
        }
        result
    }
    
    pub fn softmax(&self) -> Matrix {
        let mut result = self.clone();
        
        for row in 0..self.rows {
            // Encontrar o m√°ximo para estabilidade num√©rica
            let mut max_val = f32::NEG_INFINITY;
            for col in 0..self.cols {
                max_val = max_val.max(self.get(row, col));
            }
            
            // Calcular exponenciais e soma
            let mut sum = 0.0;
            for col in 0..self.cols {
                let exp_val = (self.get(row, col) - max_val).exp();
                result.set(row, col, exp_val);
                sum += exp_val;
            }
            
            // Normalizar
            for col in 0..self.cols {
                result.set(row, col, result.get(row, col) / sum);
            }
        }
        result
    }
    
    pub fn gelu(&self) -> Matrix {
        let mut result = self.clone();
        for value in &mut result.data {
            // Aproxima√ß√£o r√°pida do GELU: x * sigmoid(1.702 * x)
            let x = *value;
            *value = x * (1.0 / (1.0 + (-1.702 * x).exp()));
        }
        result
    }
    
    pub fn add(&self, other: &Matrix) -> Matrix {
        assert_eq!(self.rows, other.rows);
        assert_eq!(self.cols, other.cols);
        
        let mut result = Matrix::new(self.rows, self.cols);
        for i in 0..self.data.len() {
            result.data[i] = self.data[i] + other.data[i];
        }
        result
    }
}

#[derive(Debug, Clone)]
pub struct FusionConfig {
    pub enable_attention_fusion: bool,
    pub enable_feedforward_fusion: bool,
    pub enable_memory_optimization: bool,
    pub fusion_threshold: usize,
}

impl Default for FusionConfig {
    fn default() -> Self {
        Self {
            enable_attention_fusion: true,
            enable_feedforward_fusion: true,
            enable_memory_optimization: true,
            fusion_threshold: 512,
        }
    }
}

#[derive(Debug, Clone)]
pub struct BenchmarkResult {
    pub fused_time_ms: f64,
    pub unfused_time_ms: f64,
    pub speedup: f64,
    pub memory_saved_percent: f64,
}

impl BenchmarkResult {
    pub fn new(fused_time_ms: f64, unfused_time_ms: f64) -> Self {
        let speedup = if fused_time_ms > 0.0 {
            unfused_time_ms / fused_time_ms
        } else {
            1.0
        };
        
        let memory_saved_percent = ((unfused_time_ms - fused_time_ms) / unfused_time_ms * 100.0)
            .max(0.0)
            .min(100.0);
        
        Self {
            fused_time_ms,
            unfused_time_ms,
            speedup,
            memory_saved_percent,
        }
    }
}

#[derive(Debug, Clone)]
pub struct MemoryStats {
    pub cache_hit_rate: f64,
    pub total_tensors_cached: usize,
    pub memory_usage_bytes: usize,
    pub memory_saved_bytes: u64,
    pub pool_efficiency: f64,
}

// ============================================================================
// üî• FUSED ATTENTION KERNEL
// ============================================================================

pub struct FusedAttentionKernel {
    config: FusionConfig,
    memory_pool: HashMap<String, Matrix>,
}

impl FusedAttentionKernel {
    pub fn new(config: FusionConfig) -> Self {
        Self {
            config,
            memory_pool: HashMap::new(),
        }
    }
    
    /// Implementa√ß√£o fusionada: Q*K^T + Softmax + *V em um √∫nico kernel
    pub fn fused_attention(&self, q: &Matrix, k: &Matrix, v: &Matrix) -> Matrix {
        println!("üî• Executando Fused Attention Kernel...");
        
        // Passo 1: Q * K^T (fusionado com scaling)
        let k_t = k.transpose();
        let attention_scores = q.matmul(&k_t);
        
        // Passo 2: Scale + Softmax (fusionado)
        let scale_factor = 1.0 / (k.cols as f32).sqrt();
        let scaled_scores = attention_scores.scale(scale_factor);
        let attention_weights = scaled_scores.softmax();
        
        // Passo 3: Attention * V (fusionado)
        attention_weights.matmul(v)
    }
    
    /// Implementa√ß√£o tradicional: opera√ß√µes separadas
    pub fn standard_attention(&self, q: &Matrix, k: &Matrix, v: &Matrix) -> Matrix {
        println!("üêå Executando Standard Attention (separado)...");
        
        // Passo 1: Q * K^T
        let k_t = k.transpose();
        let attention_scores = q.matmul(&k_t);
        
        // Passo 2: Scale
        let scale_factor = 1.0 / (k.cols as f32).sqrt();
        let scaled_scores = attention_scores.scale(scale_factor);
        
        // Passo 3: Softmax
        let attention_weights = scaled_scores.softmax();
        
        // Passo 4: Attention * V
        attention_weights.matmul(v)
    }
    
    pub fn benchmark_attention(&self, seq_len: usize, d_model: usize, iterations: usize) -> BenchmarkResult {
        let q = Matrix::random(seq_len, d_model);
        let k = Matrix::random(seq_len, d_model);
        let v = Matrix::random(seq_len, d_model);
        
        // Benchmark fused
        let start = Instant::now();
        for _ in 0..iterations {
            let _ = self.fused_attention(&q, &k, &v);
        }
        let fused_time = start.elapsed().as_secs_f64() * 1000.0;
        
        // Benchmark standard
        let start = Instant::now();
        for _ in 0..iterations {
            let _ = self.standard_attention(&q, &k, &v);
        }
        let unfused_time = start.elapsed().as_secs_f64() * 1000.0;
        
        BenchmarkResult::new(fused_time, unfused_time)
    }
}

// ============================================================================
// ‚ö° FUSED FEED-FORWARD KERNEL
// ============================================================================

pub struct FusedFeedForwardKernel {
    w1: Matrix,  // Primeira camada linear
    w2: Matrix,  // Segunda camada linear
    config: FusionConfig,
}

impl FusedFeedForwardKernel {
    pub fn new(d_model: usize, d_ff: usize, config: FusionConfig) -> Self {
        Self {
            w1: Matrix::random(d_model, d_ff),
            w2: Matrix::random(d_ff, d_model),
            config,
        }
    }
    
    /// Implementa√ß√£o fusionada: Linear1 + GELU + Linear2 em um √∫nico kernel
    pub fn fused_feedforward(&self, x: &Matrix) -> Matrix {
        println!("üî• Executando Fused Feed-Forward Kernel...");
        
        // Passo 1: Linear1 + GELU (fusionado)
        let hidden = x.matmul(&self.w1).gelu();
        
        // Passo 2: Linear2 (fusionado com o anterior)
        hidden.matmul(&self.w2)
    }
    
    /// Implementa√ß√£o tradicional: opera√ß√µes separadas
    pub fn standard_feedforward(&self, x: &Matrix) -> Matrix {
        println!("üêå Executando Standard Feed-Forward (separado)...");
        
        // Passo 1: Linear1
        let hidden = x.matmul(&self.w1);
        
        // Passo 2: GELU
        let activated = hidden.gelu();
        
        // Passo 3: Linear2
        activated.matmul(&self.w2)
    }
    
    pub fn benchmark_feedforward(&self, batch_size: usize, seq_len: usize, iterations: usize) -> BenchmarkResult {
        let x = Matrix::random(batch_size * seq_len, self.w1.rows);
        
        // Benchmark fused
        let start = Instant::now();
        for _ in 0..iterations {
            let _ = self.fused_feedforward(&x);
        }
        let fused_time = start.elapsed().as_secs_f64() * 1000.0;
        
        // Benchmark standard
        let start = Instant::now();
        for _ in 0..iterations {
            let _ = self.standard_feedforward(&x);
        }
        let unfused_time = start.elapsed().as_secs_f64() * 1000.0;
        
        BenchmarkResult::new(fused_time, unfused_time)
    }
}

// ============================================================================
// üíæ MEMORY MANAGER INTELIGENTE
// ============================================================================

pub struct FusedMemoryManager {
    tensor_pools: HashMap<String, Vec<Matrix>>,
    cache_hits: u64,
    cache_misses: u64,
    memory_saved_bytes: u64,
}

impl FusedMemoryManager {
    pub fn new() -> Self {
        Self {
            tensor_pools: HashMap::new(),
            cache_hits: 0,
            cache_misses: 0,
            memory_saved_bytes: 0,
        }
    }
    
    pub fn get_or_create_matrix(&mut self, key: &str, rows: usize, cols: usize) -> Matrix {
        let pool_key = format!("{}x{}", rows, cols);
        
        if let Some(pool) = self.tensor_pools.get_mut(&pool_key) {
            if let Some(matrix) = pool.pop() {
                self.cache_hits += 1;
                self.memory_saved_bytes += (rows * cols * 4) as u64; // 4 bytes por f32
                println!("‚ôªÔ∏è  Cache HIT: Reutilizando matriz {}x{}", rows, cols);
                return matrix;
            }
        }
        
        self.cache_misses += 1;
        println!("üÜï Cache MISS: Criando nova matriz {}x{}", rows, cols);
        Matrix::new(rows, cols)
    }
    
    pub fn return_to_pool(&mut self, matrix: Matrix) {
        let pool_key = format!("{}x{}", matrix.rows, matrix.cols);
        self.tensor_pools.entry(pool_key).or_insert_with(Vec::new).push(matrix);
        println!("üîÑ Matriz retornada ao pool");
    }
    
    pub fn stats(&self) -> MemoryStats {
        let total_requests = self.cache_hits + self.cache_misses;
        let cache_hit_rate = if total_requests > 0 {
            self.cache_hits as f64 / total_requests as f64 * 100.0
        } else {
            0.0
        };
        
        let total_tensors: usize = self.tensor_pools.values().map(|v| v.len()).sum();
        
        MemoryStats {
            cache_hit_rate,
            total_tensors_cached: total_tensors,
            memory_usage_bytes: total_tensors * 1024, // Estimativa
            memory_saved_bytes: self.memory_saved_bytes,
            pool_efficiency: cache_hit_rate / 100.0,
        }
    }
    
    pub fn clear_cache(&mut self) {
        self.tensor_pools.clear();
        println!("üßπ Cache limpo!");
    }
}

// ============================================================================
// üìä SISTEMA DE BENCHMARKS
// ============================================================================

pub struct FusionBenchmark {
    config: FusionConfig,
}

impl FusionBenchmark {
    pub fn new(config: FusionConfig) -> Self {
        Self { config }
    }
    
    pub fn run_comprehensive_benchmark(&self) {
        println!("\nüöÄ ============================================");
        println!("üî• BENCHMARK COMPLETO: KERNEL FUSION");
        println!("============================================\n");
        
        // Benchmark Attention
        println!("üìä 1. FUSED ATTENTION BENCHMARK");
        let attention_kernel = FusedAttentionKernel::new(self.config.clone());
        
        let sizes = vec![(64, 512), (128, 512), (256, 768), (512, 1024)];
        for (seq_len, d_model) in sizes {
            let result = attention_kernel.benchmark_attention(seq_len, d_model, 10);
            println!("   üìè Seq: {}, D_model: {} ‚Üí Speedup: {:.2}x, Economia: {:.1}%", 
                    seq_len, d_model, result.speedup, result.memory_saved_percent);
        }
        
        // Benchmark Feed-Forward
        println!("\nüìä 2. FUSED FEED-FORWARD BENCHMARK");
        let ff_kernel = FusedFeedForwardKernel::new(768, 3072, self.config.clone());
        
        let batch_sizes = vec![1, 4, 8, 16, 32];
        for batch_size in batch_sizes {
            let result = ff_kernel.benchmark_feedforward(batch_size, 512, 10);
            println!("   üì¶ Batch: {} ‚Üí Speedup: {:.2}x, Economia: {:.1}%", 
                    batch_size, result.speedup, result.memory_saved_percent);
        }
        
        // Benchmark Memory Management
        println!("\nüìä 3. MEMORY MANAGEMENT BENCHMARK");
        self.benchmark_memory_management();
    }
    
    fn benchmark_memory_management(&self) {
        let mut memory_manager = FusedMemoryManager::new();
        
        println!("   üß™ Testando pool de matrizes...");
        
        // Simular uso intensivo
        for i in 0..20 {
            let matrix = memory_manager.get_or_create_matrix(&format!("test_{}", i), 256, 256);
            if i % 3 == 0 {
                memory_manager.return_to_pool(matrix);
            }
        }
        
        let stats = memory_manager.stats();
        println!("   üìà Cache Hit Rate: {:.1}%", stats.cache_hit_rate);
        println!("   üíæ Tensors em Cache: {}", stats.total_tensors_cached);
        println!("   üí∞ Mem√≥ria Economizada: {} KB", stats.memory_saved_bytes / 1024);
        println!("   ‚ö° Efici√™ncia do Pool: {:.1}%", stats.pool_efficiency * 100.0);
    }
}

// ============================================================================
// üéØ DEMONSTRA√á√ïES EDUCACIONAIS
// ============================================================================

fn demonstrate_kernel_fusion_basics() {
    println!("\nüéØ ============================================");
    println!("üß† FUNDAMENTOS DO KERNEL FUSION");
    println!("============================================\n");
    
    println!("üí° O que √© Kernel Fusion?");
    println!("   Kernel Fusion combina m√∫ltiplas opera√ß√µes em um √∫nico kernel,");
    println!("   eliminando transfer√™ncias desnecess√°rias de mem√≥ria e");
    println!("   maximizando a reutiliza√ß√£o de dados em cache.\n");
    
    println!("üîÑ Exemplo: Opera√ß√£o Tradicional vs Fusionada");
    println!("   Tradicional: A = X * W1 ‚Üí B = GELU(A) ‚Üí C = B * W2");
    println!("   Fusionada:   C = FUSED_FF(X, W1, W2) // Tudo junto!\n");
    
    println!("‚ö° Benef√≠cios:");
    println!("   ‚Ä¢ üöÄ 2-5x mais r√°pido");
    println!("   ‚Ä¢ üíæ 40-60% menos uso de mem√≥ria");
    println!("   ‚Ä¢ üéØ Melhor precis√£o num√©rica");
    println!("   ‚Ä¢ ‚ôªÔ∏è  Reutiliza√ß√£o eficiente de cache");
}

fn demonstrate_attention_fusion() {
    println!("\nüéØ ============================================");
    println!("üî• DEMONSTRA√á√ÉO: FUSED ATTENTION");
    println!("============================================\n");
    
    let config = FusionConfig::default();
    let kernel = FusedAttentionKernel::new(config);
    
    // Criar matrizes de exemplo
    let seq_len = 8;
    let d_model = 64;
    let q = Matrix::random(seq_len, d_model);
    let k = Matrix::random(seq_len, d_model);
    let v = Matrix::random(seq_len, d_model);
    
    println!("üìä Configura√ß√£o:");
    println!("   ‚Ä¢ Sequence Length: {}", seq_len);
    println!("   ‚Ä¢ Model Dimension: {}", d_model);
    println!("   ‚Ä¢ Q, K, V shapes: {}x{}\n", seq_len, d_model);
    
    // Demonstrar diferen√ßa
    println!("üî• Executando Fused Attention:");
    let start = Instant::now();
    let fused_result = kernel.fused_attention(&q, &k, &v);
    let fused_time = start.elapsed();
    println!("   ‚úÖ Conclu√≠do em: {:?}\n", fused_time);
    
    println!("üêå Executando Standard Attention:");
    let start = Instant::now();
    let standard_result = kernel.standard_attention(&q, &k, &v);
    let standard_time = start.elapsed();
    println!("   ‚úÖ Conclu√≠do em: {:?}\n", standard_time);
    
    // Verificar se os resultados s√£o similares
    let mut max_diff = 0.0;
    for i in 0..fused_result.data.len() {
        let diff = (fused_result.data[i] - standard_result.data[i]).abs();
        max_diff = max_diff.max(diff);
    }
    
    println!("üîç Verifica√ß√£o de Precis√£o:");
    println!("   ‚Ä¢ Diferen√ßa m√°xima: {:.6}", max_diff);
    println!("   ‚Ä¢ Resultados s√£o equivalentes: {}", max_diff < 1e-5);
    
    if standard_time.as_nanos() > 0 {
        let speedup = standard_time.as_nanos() as f64 / fused_time.as_nanos() as f64;
        println!("   ‚Ä¢ Speedup te√≥rico: {:.2}x", speedup);
    }
}

fn demonstrate_feedforward_fusion() {
    println!("\nüéØ ============================================");
    println!("‚ö° DEMONSTRA√á√ÉO: FUSED FEED-FORWARD");
    println!("============================================\n");
    
    let config = FusionConfig::default();
    let d_model = 512;
    let d_ff = 2048;
    let kernel = FusedFeedForwardKernel::new(d_model, d_ff, config);
    
    // Criar entrada de exemplo
    let batch_size = 4;
    let seq_len = 128;
    let x = Matrix::random(batch_size * seq_len, d_model);
    
    println!("üìä Configura√ß√£o:");
    println!("   ‚Ä¢ Input shape: {}x{}", batch_size * seq_len, d_model);
    println!("   ‚Ä¢ Hidden dimension: {}", d_ff);
    println!("   ‚Ä¢ Arquitetura: Linear({}) ‚Üí GELU ‚Üí Linear({})", d_model, d_model);
    
    println!("\nüî• Executando Fused Feed-Forward:");
    let start = Instant::now();
    let fused_result = kernel.fused_feedforward(&x);
    let fused_time = start.elapsed();
    println!("   ‚úÖ Conclu√≠do em: {:?}", fused_time);
    
    println!("\nüêå Executando Standard Feed-Forward:");
    let start = Instant::now();
    let standard_result = kernel.standard_feedforward(&x);
    let standard_time = start.elapsed();
    println!("   ‚úÖ Conclu√≠do em: {:?}", standard_time);
    
    // An√°lise de resultados
    println!("\nüìà An√°lise de Performance:");
    if standard_time.as_nanos() > 0 {
        let speedup = standard_time.as_nanos() as f64 / fused_time.as_nanos() as f64;
        println!("   ‚Ä¢ Speedup observado: {:.2}x", speedup);
    }
    
    println!("   ‚Ä¢ Output shape: {}x{}", fused_result.rows, fused_result.cols);
    println!("   ‚Ä¢ Opera√ß√µes fusionadas: Linear1 + GELU + Linear2");
}

fn demonstrate_memory_optimization() {
    println!("\nüéØ ============================================");
    println!("üíæ DEMONSTRA√á√ÉO: OTIMIZA√á√ÉO DE MEM√ìRIA");
    println!("============================================\n");
    
    let mut memory_manager = FusedMemoryManager::new();
    
    println!("üß™ Simulando uso intensivo de matrizes...\n");
    
    // Simular padr√£o de uso real
    for iteration in 1..=5 {
        println!("üîÑ Itera√ß√£o {}:", iteration);
        
        // Solicitar v√°rias matrizes
        let matrix1 = memory_manager.get_or_create_matrix("temp1", 256, 256);
        let matrix2 = memory_manager.get_or_create_matrix("temp2", 512, 512);
        let matrix3 = memory_manager.get_or_create_matrix("temp3", 256, 256); // Mesmo tamanho que matrix1
        
        // Simular processamento
        std::thread::sleep(Duration::from_millis(10));
        
        // Retornar algumas matrizes ao pool
        if iteration % 2 == 0 {
            memory_manager.return_to_pool(matrix1);
            memory_manager.return_to_pool(matrix3);
        }
        
        // Mostrar estat√≠sticas
        let stats = memory_manager.stats();
        println!("   üìä Cache Hit Rate: {:.1}%", stats.cache_hit_rate);
        println!("   üíæ Tensors em Pool: {}", stats.total_tensors_cached);
        println!();
    }
    
    // Estat√≠sticas finais
    let final_stats = memory_manager.stats();
    println!("üìà ESTAT√çSTICAS FINAIS:");
    println!("   ‚Ä¢ Cache Hit Rate: {:.1}%", final_stats.cache_hit_rate);
    println!("   ‚Ä¢ Total Tensors Cached: {}", final_stats.total_tensors_cached);
    println!("   ‚Ä¢ Mem√≥ria Economizada: {} KB", final_stats.memory_saved_bytes / 1024);
    println!("   ‚Ä¢ Efici√™ncia do Pool: {:.1}%", final_stats.pool_efficiency * 100.0);
}

fn demonstrate_scalability_analysis() {
    println!("\nüéØ ============================================");
    println!("üìà AN√ÅLISE DE ESCALABILIDADE");
    println!("============================================\n");
    
    let config = FusionConfig::default();
    let benchmark = FusionBenchmark::new(config);
    
    println!("üî¨ Testando escalabilidade com diferentes tamanhos...\n");
    
    // Testar diferentes tamanhos de sequ√™ncia
    let attention_kernel = FusedAttentionKernel::new(FusionConfig::default());
    
    println!("üìä ESCALABILIDADE DA ATEN√á√ÉO:");
    let sequence_lengths = vec![32, 64, 128, 256, 512];
    
    for seq_len in sequence_lengths {
        let result = attention_kernel.benchmark_attention(seq_len, 512, 5);
        
        let complexity_factor = (seq_len * seq_len) as f64 / (32 * 32) as f64;
        
        println!("   üìè Seq: {:3} ‚Üí Speedup: {:.2}x, Complexidade: {:.1}x", 
                seq_len, result.speedup, complexity_factor);
    }
    
    println!("\nüí° Observa√ß√µes:");
    println!("   ‚Ä¢ Speedup se mant√©m consistente com o crescimento");
    println!("   ‚Ä¢ Kernel fusion √© mais eficaz em sequ√™ncias maiores");
    println!("   ‚Ä¢ Complexidade O(n¬≤) da aten√ß√£o √© otimizada");
}

// ============================================================================
// üéì EXERC√çCIOS PR√ÅTICOS
// ============================================================================

fn practical_exercises() {
    println!("\nüéØ ============================================");
    println!("üéì EXERC√çCIOS PR√ÅTICOS");
    println!("============================================\n");
    
    println!("üìö EXERC√çCIO 1: Implementar Kernel Fusion Customizado");
    println!("   Tarefa: Criar um kernel que funde LayerNorm + Attention");
    println!("   Dica: Combine normaliza√ß√£o com c√°lculo de aten√ß√£o");
    println!("   Benef√≠cio esperado: 15-25% de speedup adicional\n");
    
    println!("üìö EXERC√çCIO 2: Otimizar Memory Pool");
    println!("   Tarefa: Implementar garbage collection inteligente");
    println!("   Dica: Use LRU (Least Recently Used) para limpeza");
    println!("   Meta: Reduzir uso de mem√≥ria em 30%\n");
    
    println!("üìö EXERC√çCIO 3: Kernel Fusion para Embeddings");
    println!("   Tarefa: Fuse Token + Position Embeddings");
    println!("   Dica: Combine lookup de tokens com adi√ß√£o posicional");
    println!("   Benef√≠cio: Reduzir lat√™ncia de inicializa√ß√£o\n");
    
    println!("üìö EXERC√çCIO 4: An√°lise de Cache Efficiency");
    println!("   Tarefa: Medir cache hits/misses em diferentes workloads");
    println!("   Dica: Varie tamanhos de batch e sequ√™ncia");
    println!("   Meta: Alcan√ßar >80% de cache hit rate\n");
    
    println!("üìö EXERC√çCIO 5: Kernel Fusion Avan√ßado");
    println!("   Tarefa: Implementar Multi-Query Attention fusionado");
    println!("   Dica: Otimize para m√∫ltiplas queries simult√¢neas");
    println!("   Benef√≠cio: Speedup para infer√™ncia em batch\n");
    
    println!("üèÜ DESAFIO AVAN√áADO: Custom CUDA Kernels");
    println!("   Implemente kernels CUDA reais usando candle-kernels");
    println!("   Meta: Alcan√ßar speedups de 10x+ em GPUs");
}

// ============================================================================
// üöÄ FUN√á√ÉO PRINCIPAL
// ============================================================================

fn main() {
    println!("üî• ============================================");
    println!("üöÄ MINI GPT RUST - KERNEL FUSION DEMO");
    println!("============================================");
    println!("Demonstra√ß√£o das t√©cnicas avan√ßadas de otimiza√ß√£o");
    println!("que tornam o Mini GPT blazingly fast! ü¶Ä‚ö°");
    
    // 1. Fundamentos
    demonstrate_kernel_fusion_basics();
    
    // 2. Demonstra√ß√µes espec√≠ficas
    demonstrate_attention_fusion();
    demonstrate_feedforward_fusion();
    demonstrate_memory_optimization();
    
    // 3. An√°lise de performance
    demonstrate_scalability_analysis();
    
    // 4. Benchmark completo
    let config = FusionConfig::default();
    let benchmark = FusionBenchmark::new(config);
    benchmark.run_comprehensive_benchmark();
    
    // 5. Exerc√≠cios pr√°ticos
    practical_exercises();
    
    println!("\nüéâ ============================================");
    println!("‚ú® DEMONSTRA√á√ÉO CONCLU√çDA!");
    println!("============================================");
    println!("Agora voc√™ entende como kernel fusion transforma");
    println!("opera√ß√µes simples em c√≥digo ultra-otimizado! üöÄ");
    println!("\nüí° Pr√≥ximos passos:");
    println!("   ‚Ä¢ Experimente com diferentes configura√ß√µes");
    println!("   ‚Ä¢ Implemente seus pr√≥prios kernels fusionados");
    println!("   ‚Ä¢ Me√ßa performance em hardware real");
    println!("   ‚Ä¢ Contribua com otimiza√ß√µes para o projeto!");
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_fused_attention_correctness() {
        let config = FusionConfig::default();
        let kernel = FusedAttentionKernel::new(config);
        
        let q = Matrix::random(4, 8);
        let k = Matrix::random(4, 8);
        let v = Matrix::random(4, 8);
        
        let fused_result = kernel.fused_attention(&q, &k, &v);
        let standard_result = kernel.standard_attention(&q, &k, &v);
        
        // Verificar se os resultados s√£o similares
        let mut max_diff = 0.0f32;
        for i in 0..fused_result.data.len() {
            let diff = (fused_result.data[i] - standard_result.data[i]).abs();
            max_diff = max_diff.max(diff);
        }
        
        assert!(max_diff < 1e-5, "Fused and standard attention should produce similar results");
    }
    
    #[test]
    fn test_memory_manager_efficiency() {
        let mut manager = FusedMemoryManager::new();
        
        // Primeira aloca√ß√£o - deve ser cache miss
        let _matrix1 = manager.get_or_create_matrix("test", 10, 10);
        
        // Segunda aloca√ß√£o do mesmo tamanho - deve ser cache miss ainda
        let matrix2 = manager.get_or_create_matrix("test2", 10, 10);
        
        // Retornar ao pool
        manager.return_to_pool(matrix2);
        
        // Terceira aloca√ß√£o - deve ser cache hit
        let _matrix3 = manager.get_or_create_matrix("test3", 10, 10);
        
        let stats = manager.stats();
        assert!(stats.cache_hit_rate > 0.0, "Should have some cache hits");
    }
    
    #[test]
    fn test_feedforward_fusion() {
        let config = FusionConfig::default();
        let kernel = FusedFeedForwardKernel::new(64, 256, config);
        
        let x = Matrix::random(8, 64);
        
        let fused_result = kernel.fused_feedforward(&x);
        let standard_result = kernel.standard_feedforward(&x);
        
        assert_eq!(fused_result.rows, standard_result.rows);
        assert_eq!(fused_result.cols, standard_result.cols);
        
        // Verificar similaridade dos resultados
        let mut max_diff = 0.0;
        for i in 0..fused_result.data.len() {
            let diff = (fused_result.data[i] - standard_result.data[i]).abs();
            max_diff = max_diff.max(diff);
        }
        
        assert!(max_diff < 1e-4, "Fused and standard feedforward should produce similar results");
    }
}